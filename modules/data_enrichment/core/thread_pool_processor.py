# modules_new/core/thread_pool_processor.py
"""
å¤šçº¿ç¨‹å¤„ç†å™¨ - åŸºäºAPIé€Ÿç‡é™åˆ¶çš„æ™ºèƒ½å¹¶å‘å¤„ç†

åŸºäºGemini 2.5 Flash APIé™åˆ¶ä¼˜åŒ–:
- TPM (æ¯åˆ†é’ŸTokenæ•°): 1,000,000
- RPD (æ¯æ—¥è¯·æ±‚æ•°): 10,000
"""

import time
import threading
import queue
import logging
from typing import Any, Dict, List, Optional, Callable, TYPE_CHECKING
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import math
import os
import pandas as pd # Moved import to top

from ..core.exceptions import with_error_handling
from ..utils.file_utils import FileUtils # Moved import to top
from ..config.api_config import APIConfig # Corrected import

if TYPE_CHECKING:
    from ..core.status_tracker import StatusTracker
    from ..config.api_config import APIConfig # Added correct TYPE_CHECKING import


@dataclass
class APILimits:
    """APIé€Ÿç‡é™åˆ¶é…ç½®"""
    tokens_per_minute: int = 1_000_000  # TPM: 1,000,000
    requests_per_day: int = 10_000      # RPD: 10,000
    estimated_tokens_per_request: int = 2000  # ä¼°ç®—æ¯ä¸ªè¯·æ±‚çš„tokenæ•°
    max_concurrent_threads_override: Optional[int] = None # å…è®¸ç”¨æˆ·è¦†ç›–æœ€å¤§çº¿ç¨‹æ•°

    def __post_init__(self):
        """éªŒè¯å’Œä¿®æ­£é…ç½®å‚æ•°"""
        # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯æ­£æ•°
        if self.tokens_per_minute <= 0:
            self.tokens_per_minute = 1_000_000
        if self.requests_per_day <= 0:
            self.requests_per_day = 10_000
        if self.estimated_tokens_per_request <= 0:
            self.estimated_tokens_per_request = 2000

    @classmethod
    def from_api_config(cls, config: 'APIConfig'):
        """ä»APIConfigåˆ›å»ºAPILimitså®ä¾‹"""
        if not config:
            return cls()

        return cls(
            tokens_per_minute=getattr(config, 'tokens_per_minute', 1_000_000),
            requests_per_day=getattr(config, 'requests_per_day', 10_000),
            estimated_tokens_per_request=getattr(config, 'estimated_tokens_per_request', 2000),
            max_concurrent_threads_override=getattr(config, 'max_concurrent_threads', None) if getattr(config, 'auto_optimize', False) else None
        )

    @property
    def max_requests_per_minute(self) -> int:
        """åŸºäºTokené™åˆ¶è®¡ç®—æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°"""
        # é˜²æ­¢é™¤é›¶é”™è¯¯
        if self.estimated_tokens_per_request <= 0:
            tokens_based_limit = self.tokens_per_minute // 2000  # ä½¿ç”¨é»˜è®¤å€¼2000
        else:
            tokens_based_limit = self.tokens_per_minute // self.estimated_tokens_per_request
        
        return min(
            tokens_based_limit,
            self.requests_per_day // (24 * 60)  # å¹³å‡æ¯åˆ†é’Ÿè¯·æ±‚æ•°
        )
    
    @property
    def optimal_delay_seconds(self) -> float:
        """è®¡ç®—æœ€ä¼˜è¯·æ±‚é—´éš”"""
        max_rpm = self.max_requests_per_minute
        if max_rpm <= 0:
            return 1.0  # é»˜è®¤1ç§’é—´éš”
        return 60.0 / max_rpm
    
    @property
    def max_concurrent_threads(self) -> int:
        """è®¡ç®—æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°"""
        if self.max_concurrent_threads_override:
            return self.max_concurrent_threads_override
            
        # è€ƒè™‘APIå“åº”æ—¶é—´ï¼ˆä¼°è®¡5-15ç§’ï¼‰ï¼Œè®¡ç®—åˆç†çš„å¹¶å‘æ•°
        avg_response_time = 10  # ç§’
        max_rpm = self.max_requests_per_minute
        
        # é˜²æ­¢é™¤é›¶æˆ–è´Ÿæ•°
        if max_rpm <= 0:
            return 2  # æœ€å°çº¿ç¨‹æ•°
            
        calculated_threads = int(max_rpm * avg_response_time / 60)
        return min(8, max(2, calculated_threads))


@dataclass
class ProcessingTask:
    """å¤„ç†ä»»åŠ¡"""
    index: int
    data: Dict[str, Any]
    chemical_name: str
    retry_count: int = 0


class ThreadPoolProcessor:
    """å¤šçº¿ç¨‹å¤„ç†å™¨ä¸»ç±»"""
    
    def __init__(self, module_manager):
        self.module_manager = module_manager
        self.api_config_manager = self.module_manager.get_module('api_config_manager')
        self.status_tracker = self.module_manager.get_module('status_tracker')
        self.api_limits = self._get_api_limits_from_config()
        
        self.is_stopped = False
        self.is_paused = False
        self.rate_limit_lock = threading.Lock()
        self.requests_this_minute = 0
        self.minute_start_time = time.time()
        
        self.logger = logging.getLogger(self.__class__.__name__)

        # ç”¨äºåˆ†æ‰¹å¤„ç†å’Œå¤‡ä»½
        self.processed_count_since_last_batch = 0
        # Removed self.processed_count_since_last_backup
        self.current_batch_results = []
        self.batch_number = 0

    def _get_api_limits_from_config(self) -> APILimits:
        """ä»APIé…ç½®ç®¡ç†å™¨è·å–APILimits"""
        if self.api_config_manager:
            try:
                # é€‚é…ä¸åŒçš„APIé…ç½®ç®¡ç†å™¨ç±»å‹
                if hasattr(self.api_config_manager, 'get_current_api_config'):
                    current_config = self.api_config_manager.get_current_api_config()
                elif hasattr(self.api_config_manager, 'get_current_config'):
                    current_config = self.api_config_manager.get_current_config()
                else:
                    current_config = None
                
                if current_config:
                    # å¦‚æœé…ç½®æœ‰to_api_limitsæ–¹æ³•ï¼Œä½¿ç”¨å®ƒ
                    if hasattr(current_config, 'to_api_limits'):
                        result = current_config.to_api_limits()
                        # ç¡®ä¿è¿”å›çš„æ˜¯ APILimits å¯¹è±¡ï¼Œè€Œä¸æ˜¯å­—å…¸
                        if isinstance(result, dict):
                            return APILimits(**result)
                        elif isinstance(result, APILimits):
                            return result
                    
                    # å¦åˆ™ä»é…ç½®å±æ€§åˆ›å»ºAPILimits
                    return APILimits.from_api_config(current_config)
            except Exception as e:
                self.logger.warning(f"æ— æ³•ä»é…ç½®è·å–APIé™åˆ¶: {e}")
        
        # å›é€€åˆ°é»˜è®¤å€¼
        return APILimits()

    def _wait_for_rate_limit(self):
        """ç­‰å¾…é€Ÿç‡é™åˆ¶"""
        with self.rate_limit_lock:
            current_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®åˆ†é’Ÿè®¡æ•°å™¨
            if current_time - self.minute_start_time >= 60:
                self.requests_this_minute = 0
                self.minute_start_time = current_time
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ¯åˆ†é’Ÿé™åˆ¶
            if self.requests_this_minute >= self.api_limits.max_requests_per_minute:
                wait_time = 60 - (current_time - self.minute_start_time)
                if wait_time > 0:
                    self.logger.info(f"â³ è¾¾åˆ°æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
                    time.sleep(wait_time)
                    self.requests_this_minute = 0
                    self.minute_start_time = time.time()
            
            # è®°å½•è¯·æ±‚
            self.requests_this_minute += 1
            
            # åŸºæœ¬é—´éš”ç­‰å¾…
            time.sleep(self.api_limits.optimal_delay_seconds)

    def _backup_results(self, df_to_backup: pd.DataFrame): # Modified signature to accept DataFrame
        """å¤‡ä»½å½“å‰å¤„ç†çš„ç»“æœ"""
        backup_manager = self.module_manager.get_module('backup_manager')
        if not backup_manager:
            self.logger.warning("å¤‡ä»½ç®¡ç†å™¨æœªåŠ è½½ï¼Œè·³è¿‡å¤‡ä»½")
            return

        try:
            # Removed DataFrame conversion, now accepts DataFrame directly

            if not df_to_backup.empty:
                # Using batch_number for backup filename consistency
                # Modified backup method call from backup_dataframe to create_backup
                backup_manager.create_backup(df_to_backup, f"batch_backup_{self.batch_number}")
                if self.log_callback:
                    self.log_callback(f"ğŸ“¦ å·²åˆ›å»ºå¤‡ä»½ï¼ŒåŒ…å« {len(df_to_backup)} æ¡è®°å½•", "INFO")
        except Exception as e:
            self.logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")

    def _save_batch_results(self):
        """ä¿å­˜å½“å‰æ‰¹æ¬¡çš„ç»“æœå¹¶åˆ›å»ºç›‘æ§å¿«ç…§"""
        if not self.current_batch_results:
            return

        self.batch_number += 1
        
        try:
            # Removed local imports for pandas and FileUtils

            df_batch = pd.DataFrame([r['data'] for r in self.current_batch_results if r.get('success')])
            
            if not df_batch.empty:
                config_manager = self.module_manager.get_module('config_manager')
                output_folder = config_manager.get_path_config().get('output_folder', 'output_batches')
                
                # åˆ›å»ºæ‰¹æ¬¡è¾“å‡ºç›®å½•
                batch_output_folder = os.path.join(output_folder, 'batches')
                FileUtils.ensure_directory(batch_output_folder) # Corrected method name
                
                output_filename = f"batch_{self.batch_number}.csv"
                output_path = os.path.join(batch_output_folder, output_filename)
                
                csv_processor = self.module_manager.get_module('csv_processor')
                csv_processor.write_csv(df_batch, output_path)
                
                if self.log_callback:
                    self.log_callback(f"ğŸ“„ å·²ä¿å­˜æ‰¹æ¬¡æ–‡ä»¶: {output_filename} (åŒ…å« {len(df_batch)} æ¡è®°å½•)", "SUCCESS")
                
                # åˆ›å»ºç›‘æ§å¿«ç…§
                self._create_monitoring_snapshot(df_batch)

                # Call backup after successful save
                self._backup_results(df_batch) # Added call to backup the saved batch

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ‰¹æ¬¡æ–‡ä»¶å¤±è´¥: {e}")
        
        finally:
            # æ¸…ç©ºå½“å‰æ‰¹æ¬¡ç»“æœ
            self.current_batch_results = []
            self.processed_count_since_last_batch = 0

    def _create_monitoring_snapshot(self, df_batch: pd.DataFrame):
        """åˆ›å»ºå¹¶è®°å½•ç›‘æ§å¿«ç…§"""
        monitoring_manager = self.module_manager.get_module('monitoring_manager')
        if not monitoring_manager:
            self.logger.debug("ç›‘æ§ç®¡ç†å™¨æœªåŠ è½½ï¼Œè·³è¿‡å¿«ç…§åˆ›å»º")
            return
        
        try:
            monitoring_manager.create_snapshot(df_batch)
            if self.log_callback:
                self.log_callback("ğŸ“Š å·²åˆ›å»ºæ–°çš„ç›‘æ§å¿«ç…§ã€‚", "DEBUG")
        except Exception as e:
            self.logger.error(f"åˆ›å»ºç›‘æ§å¿«ç…§å¤±è´¥: {e}")

    @with_error_handling()
    def process_batch(self, tasks: List[ProcessingTask], progress_callback=None, log_callback=None) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        
        # å­˜å‚¨å›è°ƒå‡½æ•°
        self.progress_callback = progress_callback
        self.log_callback = log_callback or self.module_manager.get_log_callback()
        
        # æ¯æ¬¡æ‰¹é‡å¤„ç†æ—¶éƒ½é‡æ–°è·å–æœ€æ–°çš„APIé…ç½®
        self.api_limits = self._get_api_limits_from_config()
        max_workers = self.api_limits.max_concurrent_threads

        # æ›´æ–°StatusTracker
        if self.status_tracker:
            self.status_tracker.update_stats(
                total=len(tasks),
                threads=max_workers
            )
        
        results = []
        self.is_stopped = False
        self.is_paused = False
        
        # é‡ç½®è®¡æ•°å™¨
        self.processed_count_since_last_batch = 0
        # Removed self.processed_count_since_last_backup = 0
        self.current_batch_results = []
        self.batch_number = 0
        
        if self.log_callback:
            self.log_callback(
                f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹å¤„ç†ï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹", 
                "INFO"
            )
        
        try:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_task = {
                    executor.submit(self._process_single_task, task): task
                    for task in tasks
                }
                
                for future in as_completed(future_to_task):
                    task = future_to_task.pop(future)
                    
                    while self.is_paused and not self.is_stopped:
                        time.sleep(0.5)
                    
                    if self.is_stopped:
                        if self.log_callback:
                            self.log_callback("â¹ï¸ ç”¨æˆ·åœæ­¢äº†å¤„ç†", "WARNING")
                        for f in future_to_task:
                            f.cancel()
                        break
                    
                    try:
                        result = future.result()
                        results.append(result)
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½æˆ–åˆ†æ‰¹è¾“å‡º
                        if result.get('success'):
                            # Removed self.processed_count_since_last_backup += 1
                            self.processed_count_since_last_batch += 1
                            self.current_batch_results.append(result)

                            # Removed backup check based on processed_count_since_last_backup
                            # if self.processed_count_since_last_backup >= 50:
                            #     self._backup_results(results) # This was incorrect, should use current batch
                            #     self.processed_count_since_last_backup = 0

                       
                            if self.processed_count_since_last_batch >= 100:
                                self._save_batch_results()

                    except Exception as e:
                        error_result = {
                            'index': task.index,
                            'chemical_name': task.chemical_name,
                            'success': False,
                            'error': str(e),
                            'data': task.data
                        }
                        results.append(error_result)
                        if self.status_tracker:
                            self.status_tracker.update_stats(processed=1, errors=1)
                        self.logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {task.chemical_name} - {e}")
                
        except Exception as e:
            self.logger.error(f"æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            if self.log_callback:
                self.log_callback(f"âŒ æ‰¹é‡å¤„ç†é”™è¯¯: {e}", "ERROR")
        
        # å¤„ç†æœ€åä¸€æ‰¹ä¸è¶³100æ¡çš„ç»“æœ
        self._save_batch_results()
        
        if self.log_callback:
            self.log_callback("ğŸ‰ å¤šçº¿ç¨‹å¤„ç†å®Œæˆ", "SUCCESS")
        
        return sorted(results, key=lambda x: x['index'])
    
    def _process_single_task(self, task: ProcessingTask) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_start_time = time.time()
        
        # ç­‰å¾…é€Ÿç‡é™åˆ¶
        self._wait_for_rate_limit()
        
        # æ£€æŸ¥åœæ­¢çŠ¶æ€
        if self.is_stopped:
            return {
                'index': task.index,
                'chemical_name': task.chemical_name,
                'success': False,
                'error': 'Processing stopped by user',
                'data': task.data
            }
        
        try:
            core_processor = self.module_manager.get_module('core_processor')
            if not core_processor:
                raise Exception("æ ¸å¿ƒå¤„ç†å™¨æœªåŠ è½½")
            
            # å¤„ç†å•è¡Œæ•°æ®ï¼Œç°åœ¨è¿”å›æ›´è¯¦ç»†çš„ç»“æœ
            processed_result = core_processor.process_single_row(task.data, task.chemical_name)
            
            task_time = time.time() - task_start_time
            
            # æ›´æ–°ç»Ÿè®¡
            if self.status_tracker:
                stats_update = {
                    'processed': 1,
                    'success': 1 if processed_result.get('success') else 0,
                    'errors': 0 if processed_result.get('success') else 1,
                    'api_calls': processed_result.get('api_calls', 0),
                    'api_errors': processed_result.get('api_errors', 0),
                    'parse_success': 1 if processed_result.get('parse_success') else 0,
                    'total_response_time': processed_result.get('response_time', 0),
                    'estimated_tokens': self.api_limits.estimated_tokens_per_request,
                    'task_time': task_time
                }
                self.status_tracker.update_stats(**stats_update)

            return {
                'index': task.index,
                'chemical_name': task.chemical_name,
                'success': processed_result.get('success', False),
                'data': processed_result.get('data', task.data),
                'error': processed_result.get('error'),
                'thread_id': threading.current_thread().ident
            }
            
        except Exception as e:
            self.logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥ [{task.chemical_name}]: {e}")
            if self.status_tracker:
                self.status_tracker.update_stats(processed=1, errors=1, task_time=time.time() - task_start_time)
            return {
                'index': task.index,
                'chemical_name': task.chemical_name,
                'success': False,
                'error': str(e),
                'data': task.data
            }
    
    def pause(self):
        """æš‚åœå¤„ç†"""
        self.is_paused = True
        self.logger.info("â¸ï¸ å¤šçº¿ç¨‹å¤„ç†å·²æš‚åœ")
    
    def resume(self):
        """æ¢å¤å¤„ç†"""
        self.is_paused = False
        self.logger.info("â–¶ï¸ å¤šçº¿ç¨‹å¤„ç†å·²æ¢å¤")
    
    def stop(self):
        """åœæ­¢å¤„ç†"""
        self.is_stopped = True
        self.logger.info("â¹ï¸ å¤šçº¿ç¨‹å¤„ç†å·²åœæ­¢")
