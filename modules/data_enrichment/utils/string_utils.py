# modules_new/utils/string_utils.py
"""
å­—ç¬¦ä¸²å·¥å…·ç±»

æä¾›å­—ç¬¦ä¸²å¤„ç†ç›¸å…³çš„å®ç”¨å·¥å…·
"""

import re
import unicodedata
from typing import List, Dict, Optional, Any, Tuple
import logging
import json
import pandas as pd


class StringUtils:
    """å­—ç¬¦ä¸²å·¥å…·ç±»"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼"""
        if not isinstance(text, str):
            return str(text)
        
        # ç§»é™¤å‰åç©ºæ ¼
        text = text.strip()
        
        # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        text = ''.join(char for char in text if unicodedata.category(char)[0] != 'C')
        
        return text
    
    @staticmethod
    def normalize_chemical_name(name: str) -> str:
        """æ ‡å‡†åŒ–åŒ–å­¦å“åç§°"""
        if not isinstance(name, str):
            return str(name)
        
        # åŸºç¡€æ¸…ç†
        name = StringUtils.clean_text(name)
        
        # ç§»é™¤å¸¸è§çš„éå¿…è¦å‰ç¼€/åç¼€
        prefixes_to_remove = ['åŒ–å­¦çº¯', 'åˆ†æçº¯', 'AR', 'CP', 'GR']
        for prefix in prefixes_to_remove:
            if name.startswith(prefix):
                name = name[len(prefix):].strip()
        
        # æ ‡å‡†åŒ–æ‹¬å·
        name = re.sub(r'[ï¼ˆ\(]([^ï¼‰\)]*)[ï¼‰\)]', r'(\1)', name)
        
        return name
    
    @staticmethod
    def normalize_cas_number(cas: str) -> str:
        """æ ‡å‡†åŒ–CASå·æ ¼å¼"""
        if not isinstance(cas, str):
            return str(cas)
        
        # ç§»é™¤æ‰€æœ‰ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™æ•°å­—å’Œè¿å­—ç¬¦
        cas = re.sub(r'[^\d\-]', '', cas)
        
        # éªŒè¯æ ¼å¼å¹¶æ ‡å‡†åŒ–
        cas_pattern = re.compile(r'^(\d{2,7})-(\d{2})-(\d)$')
        match = cas_pattern.match(cas)
        
        if match:
            return f"{match.group(1)}-{match.group(2)}-{match.group(3)}"
        
        return cas
    
    @staticmethod
    def validate_cas_or_serial_number(identifier: str) -> Dict[str, Any]:
        """
        éªŒè¯å’Œåˆ†æCASå·æˆ–æµæ°´å·
        
        Args:
            identifier: è¾“å…¥çš„æ ‡è¯†ç¬¦ï¼ˆCASå·æˆ–æµæ°´å·ï¼‰
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        if not identifier or str(identifier).strip() == '':
            return {
                'type': 'ç©ºå€¼',
                'is_valid': False,
                'formatted': '',
                'needs_query': True,
                'suggestion': 'éœ€è¦æŸ¥è¯¢è¡¥å……æ ‡å‡†CASå·'
            }
        
        identifier_str = str(identifier).strip()
        
        # CASå·æ ¼å¼éªŒè¯
        cas_pattern = r'^\d{2,7}-\d{2}-\d$'
        if re.match(cas_pattern, identifier_str):
            return {
                'type': 'æ ‡å‡†CASå·',
                'is_valid': True,
                'formatted': identifier_str,
                'needs_query': False,
                'suggestion': 'CASå·æ ¼å¼æ­£ç¡®ï¼Œéœ€éªŒè¯å‡†ç¡®æ€§'
            }
        
        # æµæ°´å·åˆ¤æ–­ï¼ˆçº¯æ•°å­—ï¼‰
        if identifier_str.isdigit() and len(identifier_str) >= 6:
            return {
                'type': 'æœ¬åœ°æµæ°´å·',
                'is_valid': True,
                'formatted': identifier_str,
                'needs_query': True,
                'suggestion': 'æ£€æµ‹åˆ°æœ¬åœ°æµæ°´å·ï¼Œå»ºè®®æŸ¥è¯¢å¯¹åº”çš„å›½é™…CASå·'
            }
        
        # æ ¼å¼å¼‚å¸¸
        return {
            'type': 'æ ¼å¼å¼‚å¸¸',
            'is_valid': False,
            'formatted': identifier_str,
            'needs_query': True,
            'suggestion': f'ç¼–å·æ ¼å¼ä¸æ ‡å‡†ï¼š{identifier_str}ï¼Œéœ€è¦é‡æ–°æŸ¥è¯¢éªŒè¯'
        }

    @staticmethod
    def extract_numbers(text: str) -> List[float]:
        """ä»æ–‡æœ¬ä¸­æå–æ•°å­—"""
        if not isinstance(text, str):
            return []
        
        # åŒ¹é…æ•°å­—ï¼ˆåŒ…æ‹¬å°æ•°å’Œç§‘å­¦è®¡æ•°æ³•ï¼‰
        number_pattern = r'[-+]?(?:\d*\.\d+|\d+\.?\d*)(?:[eE][-+]?\d+)?'
        matches = re.findall(number_pattern, text)
        
        numbers = []
        for match in matches:
            try:
                numbers.append(float(match))
            except ValueError:
                continue
        
        return numbers

    @staticmethod
    def is_valid_field(value: Any) -> bool:
        """
        æ£€æŸ¥å•ä¸ªå­—æ®µå€¼æ˜¯å¦æœ‰æ•ˆ
        """
        if value is None or pd.isna(value):
            return False

        # å®šä¹‰ä¸€å¥—å…¨é¢çš„æ— æ•ˆå€¼ï¼ˆä¼˜åŒ–ä¸ºé›†åˆä»¥æé«˜æŸ¥æ‰¾æ€§èƒ½ï¼‰
        invalid_values = {
            'N/A', 'NULL', 'NONE', 'æœªçŸ¥', 'æ— æ•°æ®', 'æ— ', 'ä¸è¯¦', 'UNKNOWN',
            'NOT AVAILABLE', 'NOT APPLICABLE', 'NO DATA', '/', '-', '',
            'å¾…è¡¥å……', 'ç¼ºå¤±', 'MISSING', 'TBD', 'TO BE DETERMINED', 'NA',
            'NAN', 'ç©º', 'æ— æ•ˆ', 'INVALID', 'NO INFO', 'NO INFORMATION'
        }
        
        str_value = str(value).strip()
        
        if not str_value or str_value.upper() in invalid_values:
            return False
            
        # é¢å¤–æ£€æŸ¥ï¼šä¸æ˜¯çº¯æ•°å­—çš„æ— æ„ä¹‰å­—ç¬¦ä¸²
        if str_value.isdigit() and len(str_value) < 2:
            return False
            
        return True

    @staticmethod
    def count_valid_fields(properties_data: Dict[str, Any]) -> int:
        """
        è®¡ç®—æœ‰æ•ˆå­—æ®µæ•°é‡ï¼Œä¼˜åŒ–äº†æ€§èƒ½å’Œå‡†ç¡®æ€§
        
        Args:
            properties_data: å±æ€§æ•°æ®å­—å…¸
            
        Returns:
            æœ‰æ•ˆå­—æ®µçš„æ•°é‡
        """
        if not properties_data or not isinstance(properties_data, dict):
            return 0
        
        return sum(1 for value in properties_data.values() if StringUtils.is_valid_field(value))

    @staticmethod
    def extract_units(text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å•ä½"""
        if not isinstance(text, str):
            return []
        
        # å¸¸è§å•ä½æ¨¡å¼
        unit_patterns = [
            r'Â°C|â„ƒ|K|Â°F',  # æ¸©åº¦å•ä½
            r'Pa|kPa|MPa|bar|atm|mmHg',  # å‹åŠ›å•ä½
            r'g/mol|Da|u',  # åˆ†å­é‡å•ä½
            r'g/cmÂ³|kg/mÂ³|g/mL',  # å¯†åº¦å•ä½
            r'mol/L|M|ppm|ppb|%'  # æµ“åº¦å•ä½
        ]
        
        units = []
        for pattern in unit_patterns:
            matches = re.findall(pattern, text)
            units.extend(matches)
        
        return list(set(units))  # å»é‡
    
    @staticmethod
    def is_chinese(text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        if not isinstance(text, str):
            return False
        
        return bool(re.search(r'[\u4e00-\u9fff]', text))
    
    @staticmethod
    def is_english(text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºè‹±æ–‡"""
        if not isinstance(text, str):
            return False
        
        return bool(re.match(r'^[a-zA-Z\s\-\(\)\[\]0-9,\.]+$', text))
    
    @staticmethod
    def similarity_ratio(text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
        if not isinstance(text1, str) or not isinstance(text2, str):
            return 0.0
        
        if text1 == text2:
            return 1.0
        
        # è½¬æ¢ä¸ºå°å†™
        text1 = text1.lower()
        text2 = text2.lower()
        
        # è®¡ç®—ç¼–è¾‘è·ç¦»çš„ç®€åŒ–ç‰ˆæœ¬
        len1, len2 = len(text1), len(text2)
        if len1 == 0:
            return 0.0 if len2 > 0 else 1.0
        if len2 == 0:
            return 0.0
        
        # è®¡ç®—å…±åŒå­—ç¬¦æ•°
        common_chars = 0
        for char in set(text1):
            common_chars += min(text1.count(char), text2.count(char))
        
        # ç›¸ä¼¼åº¦ = å…±åŒå­—ç¬¦æ•° / æœ€é•¿å­—ç¬¦ä¸²é•¿åº¦
        similarity = common_chars / max(len1, len2)
        return similarity
    
    @staticmethod
    def find_best_match(target: str, candidates: List[str], threshold: float = 0.6) -> Optional[str]:
        """åœ¨å€™é€‰åˆ—è¡¨ä¸­æ‰¾åˆ°æœ€ä½³åŒ¹é…"""
        if not candidates:
            return None
        
        best_match = None
        best_score = 0.0
        
        for candidate in candidates:
            score = StringUtils.similarity_ratio(target, candidate)
            if score > best_score and score >= threshold:
                best_score = score
                best_match = candidate
        
        return best_match
    
    @staticmethod
    def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
        """æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šé•¿åº¦"""
        if not isinstance(text, str):
            text = str(text)
        
        if len(text) <= max_length:
            return text
        
        return text[:max_length - len(suffix)] + suffix
    
    @staticmethod
    def mask_sensitive_info(text: str, mask_char: str = "*") -> str:
        """å±è”½æ•æ„Ÿä¿¡æ¯"""
        if not isinstance(text, str):
            return str(text)
        
        # å±è”½å¯èƒ½çš„APIå¯†é’¥
        text = re.sub(r'([a-zA-Z0-9]{20,})', lambda m: m.group(1)[:4] + mask_char * (len(m.group(1)) - 8) + m.group(1)[-4:], text)
        
        return text
    
    @staticmethod
    def generate_prompt(chemical_name: str, cas_number: Any, api_config=None) -> Optional[str]:
        """
        æ ¹æ®åŒ–å­¦å“åç§°å’ŒCASå·ç”Ÿæˆç”¨äºçŸ¥è¯†å›¾è°±æ„å»ºçš„ä¸“ä¸šåŒ–å­¦å“æ•°æ®æŸ¥è¯¢Promptã€‚
        åŒ…å«å®Œæ•´çš„åŒ–å­¦å“ä¿¡æ¯ï¼Œç”¨äºæ„å»ºåŒ–å­¦å“çŸ¥è¯†å›¾è°±ã€‚
        ç‰¹åˆ«é’ˆå¯¹"CASå·æˆ–æµæ°´å·"å­—æ®µè¿›è¡Œæ ¡éªŒå’Œå¤„ç†ã€‚
        
        Args:
            chemical_name: åŒ–å­¦å“åç§°
            cas_number: CASå·æˆ–æµæ°´å·
            api_config: APIé…ç½®å¯¹è±¡ï¼Œç”¨äºç¡®å®šæ˜¯å¦ä½¿ç”¨ç½‘ç»œæœç´¢ä¼˜åŒ–prompt
        """
        logger = logging.getLogger(StringUtils.__name__)
        logger.debug(f"å¼€å§‹ä¸ºåŒ–å­¦å“ '{chemical_name}' (CAS: {cas_number}) ç”Ÿæˆ prompt")

        try:
            # ä½¿ç”¨æ–°çš„éªŒè¯å‡½æ•°åˆ†æCASå·æˆ–æµæ°´å·
            validation_result = StringUtils.validate_cas_or_serial_number(cas_number)
            
            cas_status = f"ğŸ“‹ ç¼–å·ç±»å‹: {validation_result['type']}"
            if validation_result['is_valid']:
                cas_status += f" âœ… æ ¼å¼æœ‰æ•ˆ: {validation_result['formatted']}"
            else:
                cas_status += f" âŒ æ ¼å¼æ— æ•ˆ: {validation_result.get('formatted', 'ç©ºå€¼')}"
            
            cas_type = validation_result['type']
            validation_note = validation_result['suggestion']
            query_requirement = "ğŸ” éœ€è¦æŸ¥è¯¢è¡¥å……" if validation_result['needs_query'] else "âœ… ä»…éœ€éªŒè¯å‡†ç¡®æ€§"

            # æ£€æŸ¥APIæ˜¯å¦æ”¯æŒç½‘ç»œæœç´¢ï¼ˆè”ç½‘åŠŸèƒ½ï¼‰
            supports_web_search = False
            web_search_info = ""
            
            if api_config:
                # æ£€æŸ¥æ˜¯å¦æ”¯æŒgroundingï¼ˆGeminiï¼‰æˆ–enable_searchï¼ˆé€šä¹‰ç­‰ï¼‰
                supports_grounding = getattr(api_config, 'supports_grounding', False)
                enable_search = getattr(api_config, 'enable_search', False)
                
                if supports_grounding or enable_search:
                    supports_web_search = True
                    web_search_info = f"""
## ğŸŒ ç½‘ç»œæœç´¢å¢å¼ºæ¨¡å¼å·²å¯ç”¨
- **å½“å‰API**: {getattr(api_config, 'name', 'æœªçŸ¥')}
- **æœç´¢èƒ½åŠ›**: {'æ”¯æŒGroundingæœç´¢' if supports_grounding else 'æ”¯æŒè”ç½‘æœç´¢'}
- **æ•°æ®æºä¼˜åŠ¿**: å¯å®æ—¶è·å–æœ€æ–°çš„åŒ–å­¦å“æ•°æ®å’Œæƒå¨æ•°æ®åº“ä¿¡æ¯
- **æŸ¥è¯¢ç­–ç•¥**: ä¼˜å…ˆä½¿ç”¨ç½‘ç»œæœç´¢è·å–æœ€å‡†ç¡®çš„CASå·å’ŒåŒ–å­¦å“å±æ€§
"""

            # æ ¹æ®æ˜¯å¦æ”¯æŒç½‘ç»œæœç´¢ç”Ÿæˆä¸åŒçš„æ•°æ®æºè¦æ±‚å’ŒæŸ¥è¯¢ç­–ç•¥
            if supports_web_search:
                data_source_section = f"""{web_search_info}

## ğŸ“Š æ•°æ®æºè¦æ±‚
âš¡ **å®æ—¶ç½‘ç»œæœç´¢ç­–ç•¥**ï¼šåˆ©ç”¨è”ç½‘åŠŸèƒ½è·å–æœ€æ–°ã€æœ€å‡†ç¡®çš„åŒ–å­¦å“æ•°æ®
1. ğŸŒ **PubChem** (ç¾å›½å›½å®¶ç”Ÿç‰©æŠ€æœ¯ä¿¡æ¯ä¸­å¿ƒ) - æœ€é«˜ä¼˜å…ˆçº§ï¼ŒCASå·æƒå¨æ¥æº
2. ğŸ›ï¸ **ECHA** (æ¬§æ´²åŒ–å­¦å“ç®¡ç†å±€) - æƒå¨ç›‘ç®¡æ•°æ®ï¼Œå®æ—¶æ›´æ–°  
3. ğŸ”¬ **GESTISå›½é™…åŒ–å­¦å“æ•°æ®åº“** - å›½é™…æ ‡å‡†æ•°æ®ï¼Œè”ç½‘æŸ¥è¯¢
4. ğŸ­ **ä¾›åº”å•†SDS**: Sigma-Aldrichã€Fisher Scientificã€Merckå®˜æ–¹æœ€æ–°æ•°æ®
5. ğŸ›ï¸ **æ”¿åºœæœºæ„**: NIOSHã€OSHAã€EPAå®˜æ–¹æ•°æ®åº“ï¼Œè”ç½‘è®¿é—®
6. ğŸ“š **ä¸­å›½åŒ–å­¦å“åå½•2013å¹´ç‰ˆ** - å‚è€ƒæœ¬åœ°æµæ°´å·ä½“ç³»
7. ğŸŒ **å›½é™…åŒ–å­¦å“æ•°æ®åº“è”ç›Ÿ** - åˆ©ç”¨ç½‘ç»œæœç´¢è·å–å…¨çƒæœ€æ–°æ•°æ®

ğŸ¯ **ç½‘ç»œæœç´¢æŸ¥è¯¢é‡ç‚¹**ï¼š
- ä½¿ç”¨è”ç½‘åŠŸèƒ½éªŒè¯å’Œè¡¥å……CASå·
- å®æ—¶è·å–æœ€æ–°çš„å®‰å…¨æ•°æ®å’Œæ³•è§„ä¿¡æ¯
- æŸ¥è¯¢æœ€æ–°çš„ç‰©ç†åŒ–å­¦æ€§è´¨æ•°æ®
- è·å–æœ€æ–°çš„ç”¨é€”å’Œåº”ç”¨ä¿¡æ¯"""
            else:
                data_source_section = """
## ğŸ“Š æ•°æ®æºè¦æ±‚ (æ ‡å‡†æ¨¡å¼ - ä¸¥æ ¼æŒ‰ä¼˜å…ˆçº§)
1. ğŸŒ **PubChem** (ç¾å›½å›½å®¶ç”Ÿç‰©æŠ€æœ¯ä¿¡æ¯ä¸­å¿ƒ) - æœ€é«˜ä¼˜å…ˆçº§ï¼ŒCASå·æƒå¨æ¥æº
2. ğŸ›ï¸ **ECHA** (æ¬§æ´²åŒ–å­¦å“ç®¡ç†å±€) - æƒå¨ç›‘ç®¡æ•°æ®  
3. ğŸ”¬ **GESTISå›½é™…åŒ–å­¦å“æ•°æ®åº“** - å›½é™…æ ‡å‡†æ•°æ®
4. ğŸ­ **ä¾›åº”å•†SDS**: Sigma-Aldrichã€Fisher Scientificã€Merckå®˜æ–¹æ•°æ®
5. ğŸ›ï¸ **æ”¿åºœæœºæ„**: NIOSHã€OSHAã€EPAå®˜æ–¹æ•°æ®
6. ğŸ“š **ä¸­å›½åŒ–å­¦å“åå½•2013å¹´ç‰ˆ** - å‚è€ƒæœ¬åœ°æµæ°´å·ä½“ç³»"""

            prompt: str = f"""


## ğŸ¯ æŸ¥è¯¢ç›®æ ‡
- **åŒ–å­¦å“åç§°**: {chemical_name}
- **ç¼–å·çŠ¶æ€**: {cas_status}
- **ç¼–å·ç±»å‹**: {cas_type}
- **å¤„ç†è¦æ±‚**: {query_requirement}
- **å¤„ç†è¯´æ˜**: {validation_note}

## ğŸ” CASå·ä¸æµæ°´å·æ™ºèƒ½è¯†åˆ«æŒ‡å¼•
### ğŸ“‹ "CASå·æˆ–æµæ°´å·"å­—æ®µè¯´æ˜ï¼š
- **CASå·**ï¼šå›½é™…é€šç”¨åŒ–å­¦ç‰©è´¨å”¯ä¸€æ ‡è¯†ç¼–å·ï¼ˆæ ¼å¼ï¼šXXXX-XX-Xï¼Œå¦‚64-17-5ä»£è¡¨ä¹™é†‡ï¼‰
- **æµæ°´å·**ï¼šåå½•ç¼–åˆ¶å•ä½è‡ªå®šä¹‰ç¼–å·ï¼Œç”¨äºæ— CASå·çš„æ–°åŒ–å­¦å“ã€å¤åˆç‰©ã€ç‰¹æ®Šææ–™
- **ä¼˜å…ˆçº§**ï¼šä¼˜å…ˆä½¿ç”¨å›½é™…æ ‡å‡†CASå·ï¼Œæ— CASå·æ—¶ç”¨æœ¬åœ°æµæ°´å·ä¿è¯å”¯ä¸€æ€§

### ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼ˆæ ¹æ®ä¸Šè¿°ç¼–å·åˆ†æç»“æœï¼‰
1. **CASå·éªŒè¯ä¸è¡¥å……**ï¼šå¦‚å½“å‰ç¼–å·ä¸ºç©ºã€æ ¼å¼é”™è¯¯æˆ–ä¸ºæµæ°´å·ï¼Œå¿…é¡»æŸ¥è¯¢è¡¥å……å‡†ç¡®çš„CASå·
2. **ç¼–å·å”¯ä¸€æ€§æ£€æŸ¥**ï¼šç¡®ä¿æ¯ä¸ªåŒ–å­¦å“éƒ½æœ‰å”¯ä¸€æ ‡è¯†ç¬¦
3. **æ ¼å¼æ ‡å‡†åŒ–**ï¼šCASå·æ ¼å¼å¿…é¡»ä¸º"æ•°å­—-æ•°å­—-æ•°å­—"æ ‡å‡†æ ¼å¼
4. **æ•°æ®å…³è”æ€§éªŒè¯**ï¼šç¡®è®¤ç¼–å·ä¸åŒ–å­¦å“åç§°çš„å‡†ç¡®å¯¹åº”å…³ç³»
5. **æºæ•°æ®å…¼å®¹æ€§**ï¼šå…¼å®¹ã€Šä¸­å›½åŒ–å­¦å“åå½•2013å¹´ç‰ˆã€‹çš„"CASå·æˆ–æµæ°´å·"å­—æ®µç»“æ„

{data_source_section}

## ğŸ“‹ çŸ¥è¯†å›¾è°±å±æ€§è¦æ±‚ (ç”¨äºæ„å»ºåŒ–å­¦å“çŸ¥è¯†å›¾è°±)
è¯·ä¸ºä¸Šè¿°åŒ–å­¦å“æä¾›ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºæ„å»ºå®Œæ•´çš„åŒ–å­¦å“çŸ¥è¯†å›¾è°±ã€‚æ‰€æœ‰æ•°æ®å¿…é¡»ä»¥**ç®€ä½“ä¸­æ–‡**è¡¨è¿°ï¼Œå¹¶ç¡®ä¿å†…å®¹çš„è¯¦å°½å’Œå‡†ç¡®ã€‚

### ğŸ”¬ åŸºç¡€æ ‡è¯†ä¿¡
- **åç§°**: åŒ–å­¦å“çš„æ ‡å‡†ä¸­æ–‡åç§°
- **CASå·æˆ–æµæ°´å·**: 
  - å¦‚ä¸ºæ ‡å‡†CASå·ï¼Œä¿æŒåŸæ ¼å¼å¹¶éªŒè¯å‡†ç¡®æ€§
  - å¦‚ä¸ºæµæ°´å·ï¼ŒæŸ¥è¯¢æ˜¯å¦å­˜åœ¨å¯¹åº”CASå·å¹¶ä¼˜å…ˆä½¿ç”¨CASå·
  - å¦‚ä¸ºç©ºå€¼ï¼Œä»æƒå¨æ•°æ®åº“æŸ¥è¯¢è¡¥å……æ ‡å‡†CASå·
  - æ ¼å¼è¦æ±‚ï¼šCASå·ä¸¥æ ¼ä¸º"XXXX-XX-X"ï¼Œæµæ°´å·ä¸ºçº¯æ•°å­—
- **åˆ«å**: åŒ…å«æ‰€æœ‰å¸¸ç”¨åˆ«åï¼Œä¾‹å¦‚è‹±æ–‡åã€å•†å“åã€ä¿—ç§°ã€å­¦åç­‰ã€‚æ ¼å¼ï¼š"åˆ«å1; åˆ«å2; åˆ«å3; åˆ«å4; åˆ«å5"ï¼Œè‡³å°‘æä¾›3-5ä¸ªæœ‰ä»·å€¼çš„åˆ«åï¼Œç”¨åˆ†å·åˆ†éš”
- **åˆ†å­å¼**: å‡†ç¡®çš„åŒ–å­¦åˆ†å­å¼ï¼Œä¾‹å¦‚ "C2H6O", "H2SO4"
- **åˆ†å­é‡**: å‡†ç¡®çš„åˆ†å­é‡æ•°å€¼ï¼Œå•ä½ä¸º g/molï¼Œä¿ç•™è‡³å°‘ä¸¤ä½å°æ•°ï¼Œä¾‹å¦‚ "46.07"

### âš ï¸ å±å®³ä¸å®‰å…¨ä¿¡æ¯
- **æ˜¯å¦ä¸ºå±åŒ–å“**: åŸºäºã€Šå±é™©åŒ–å­¦å“ç›®å½•ã€‹ï¼Œå¿…é¡»æ˜ç¡®å›ç­”"æ˜¯"æˆ–"å¦"
- **æµ“åº¦é˜ˆå€¼**: å‚è€ƒåŸåå½•"æµ“åº¦é˜ˆå€¼"å­—æ®µï¼Œè¯¦ç»†è¯´æ˜æ¯’ç†å­¦æ•°æ®ï¼Œä¾‹å¦‚ "LC50(å¤§é¼ å¸å…¥): 20000 ppm/10h; LD50(å¤§é¼ ç»å£): 7060 mg/kg; LD50(å…”å­çš®è‚¤): >5000 mg/kg"
- **å±å®³**: è¯¦ç»†æè¿°å¯¹äººä½“å’Œç¯å¢ƒçš„å…·ä½“å±å®³ï¼Œéœ€åˆ†ç±»è¯´æ˜ï¼š
  - **å¥åº·å±å®³**: æ€¥æ€§æ¯’æ€§ã€çš®è‚¤è…èš€/åˆºæ¿€ã€ä¸¥é‡çœ¼æŸä¼¤/çœ¼åˆºæ¿€ã€è‡´ç™Œæ€§ã€ç”Ÿæ®–æ¯’æ€§ç­‰
  - **ç¯å¢ƒå±å®³**: å¯¹æ°´ç”Ÿç”Ÿç‰©çš„å±å®³ã€æŒä¹…æ€§ã€ç”Ÿç‰©ç´¯ç§¯æ€§ç­‰
  - **ç‰©ç†å±å®³**: æ˜“ç‡ƒæ€§ã€çˆ†ç‚¸æ€§ã€æ°§åŒ–æ€§ç­‰
- **é˜²èŒƒ**: å…·ä½“çš„é˜²æŠ¤æªæ–½å’Œæ³¨æ„äº‹é¡¹ï¼Œéœ€åˆ†ç±»è¯´æ˜ï¼š
  - **å·¥ç¨‹æ§åˆ¶**: é€šé£ç³»ç»Ÿã€å¯†é—­æ“ä½œç­‰
  - **ä¸ªä½“é˜²æŠ¤**: å‘¼å¸ç³»ç»Ÿé˜²æŠ¤ã€çœ¼ç›é˜²æŠ¤ã€èº«ä½“é˜²æŠ¤ã€æ‰‹éƒ¨é˜²æŠ¤
  - **æ“ä½œå¤„ç½®ä¸å‚¨å­˜**: æ“ä½œæ³¨æ„äº‹é¡¹ã€å‚¨å­˜æ¡ä»¶
- **å±å®³å¤„ç½®**: å‘ç”Ÿäº‹æ•…æ—¶çš„å…·ä½“åº”æ€¥å¤„ç½®æ–¹æ³•å’Œæ€¥æ•‘æªæ–½ï¼Œéœ€åˆ†ç±»è¯´æ˜ï¼š
  - **æ³„æ¼åº”æ€¥å¤„ç†**: ç¯å¢ƒã€äººå‘˜ã€å¤„ç†æ–¹æ³•
  - **ç«ç¾å¤„ç½®**: ç­ç«æ–¹æ³•ã€æœ‰å®³ç‡ƒçƒ§äº§ç‰©
  - **æ€¥æ•‘æªæ–½**: çš®è‚¤æ¥è§¦ã€çœ¼ç›æ¥è§¦ã€å¸å…¥ã€é£Ÿå…¥åçš„æ€¥æ•‘æ–¹æ³•

### ğŸ­ äº§ä¸šé“¾ä¿¡æ¯ (çŸ¥è¯†å›¾è°±æ ¸å¿ƒ)
- **ç”¨é€”**: è¯¦ç»†è¯´æ˜ä¸»è¦ç”¨é€”å’Œåº”ç”¨é¢†åŸŸï¼Œè‡³å°‘åˆ—ä¸¾5ä¸ªå…·ä½“ç”¨é€”ï¼Œå¹¶æè¿°å…¶åœ¨åº”ç”¨ä¸­æ‰®æ¼”çš„è§’è‰²
- **è‡ªç„¶æ¥æº**: è¯¦ç»†è¯´æ˜è¯¥åŒ–å­¦å“åœ¨è‡ªç„¶ç•Œä¸­çš„å­˜åœ¨å½¢å¼ã€åˆ†å¸ƒæƒ…å†µã€å¤©ç„¶æ¥æºï¼ˆå¦‚æ¤ç‰©ã€çŸ¿ç‰©ã€å¾®ç”Ÿç‰©ç­‰ï¼‰ï¼Œä»¥åŠå¤©ç„¶æå–æ–¹æ³•ã€‚å¦‚æœæ˜¯çº¯äººå·¥åˆæˆçš„åŒ–å­¦å“ï¼Œåˆ™è¯´æ˜"æ— å¤©ç„¶æ¥æºï¼Œçº¯äººå·¥åˆæˆ"
- **ç”Ÿäº§æ¥æº (ä¸Šæ¸¸)**: è¯¦ç»†åˆ—å‡ºå…¶ç›´æ¥ä¸Šæ¸¸åŸæ–™åŒ–å­¦å“ï¼Œä»¥åŠä¸»è¦çš„ç”Ÿäº§å•†æˆ–ä¾›åº”å•†ä¿¡æ¯ã€‚è¿™æ˜¯æ„å»ºäº§ä¸šé“¾ä¸Šæ¸¸å…³ç³»çš„å…³é”®
- **å·¥ä¸šç”Ÿäº§åŸæ–™ (ä¸‹æ¸¸)**: è¯¦ç»†åˆ—å‡ºè¯¥åŒ–å­¦å“ä½œä¸ºåŸæ–™å¯ä»¥ç”¨äºç”Ÿäº§å“ªäº›ä¸‹æ¸¸äº§å“æˆ–åŒ–å­¦å“ã€‚è¿™æ˜¯æ„å»ºäº§ä¸šé“¾ä¸‹æ¸¸å…³ç³»çš„å…³é”®

### âš—ï¸ ç‰©ç†åŒ–å­¦æ€§è´¨
- **æ€§è´¨**: æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„ã€ç»“æ„åŒ–çš„ç‰©ç†åŒ–å­¦æ€§è´¨æè¿°ï¼Œè‡³å°‘åŒ…æ‹¬ï¼š
  - **å¤–è§‚ä¸æ€§çŠ¶**: è¯¦ç»†æè¿°å¸¸æ¸©å¸¸å‹ä¸‹çš„é¢œè‰²ã€çŠ¶æ€ã€æ°”å‘³ç­‰æ„Ÿå®˜ç‰¹å¾
  - **ç†”ç‚¹**: æ•°å€¼+å•ä½(Â°C)ï¼Œä¾‹å¦‚ "-114.1Â°C"
  - **æ²¸ç‚¹**: æ•°å€¼+å•ä½(Â°C)ï¼Œä¾‹å¦‚ "78.3Â°C"
  - **å¯†åº¦**: æ•°å€¼+å•ä½ï¼Œå¹¶æ³¨æ˜æ¸©åº¦ï¼Œä¾‹å¦‚ "0.789 g/cmÂ³(20Â°C)"
  - **æº¶è§£æ€§**: åœ¨æ°´ã€ä¹™é†‡ç­‰å¸¸è§æº¶å‰‚ä¸­çš„æº¶è§£æƒ…å†µï¼Œå¯åŒ…å«å®šé‡æ•°æ®
  - **é—ªç‚¹**: æ•°å€¼+å•ä½(Â°C)ï¼Œå¹¶æ³¨æ˜å¼€æ¯/é—­æ¯ï¼Œä¾‹å¦‚ "13Â°C (é—­æ¯)"
  - **ç¨³å®šæ€§**: æè¿°å…¶åŒ–å­¦ç¨³å®šæ€§ã€éœ€è¦é¿å…çš„æ¡ä»¶ï¼ˆå¦‚å…‰ã€çƒ­ï¼‰å’Œç¦é…ç‰©è´¨

## ğŸ“¤ è¾“å‡ºæ ¼å¼
**å¿…é¡»ä¸¥æ ¼ä»¥JSONå¯¹è±¡æ ¼å¼è¿”å›ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µå®Œæ•´å¡«å†™ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–Markdownæ ‡è®°ã€‚**
**é‡è¦ï¼šé™¤äº† `data_source` å­—æ®µï¼Œå…¶ä»–å­—æ®µçš„æ•°æ®åä¸éœ€è¦æ ‡æ˜æ•°æ®æ¥æºã€‚**

```json
{{
    "data_source": "ç½‘ç»œæœç´¢/æ¨¡å‹çŸ¥è¯† {{æ•°æ®æ¥æº}}",
    "åç§°": "åŒ–å­¦å“æ ‡å‡†ä¸­æ–‡åç§°",
    "CASå·æˆ–æµæ°´å·": "ä¼˜å…ˆCASå·æ ¼å¼XXXX-XX-Xï¼Œæ— CASå·æ—¶ä¸ºæµæ°´å·",
    "ç¼–å·ç±»å‹è¯´æ˜": "æ ‡å‡†CASå·/æœ¬åœ°æµæ°´å·/æ–°åˆ†é…CASå·",
    "åˆ«å": "åˆ«å1; åˆ«å2; åˆ«å3",
    "åˆ†å­å¼": "åŒ–å­¦åˆ†å­å¼",
    "åˆ†å­é‡": "æ•°å€¼ g/mol",
    "æ˜¯å¦ä¸ºå±åŒ–å“": "æ˜¯/å¦",
    "æµ“åº¦é˜ˆå€¼": "æ¯’ç†å­¦æ•°æ®è¯¦æƒ…",
    "å±å®³": "å±å®³æè¿°",
    "é˜²èŒƒ": "é˜²æŠ¤æªæ–½è¯¦æƒ…",
    "å±å®³å¤„ç½®": "åº”æ€¥å¤„ç½®è¯¦æƒ…",
    "ç”¨é€”": "ç”¨é€”è¯¦æƒ…",
    "è‡ªç„¶æ¥æº": "å¤©ç„¶æ¥æºè¯¦æƒ…",
    "ç”Ÿäº§æ¥æº": "ä¸Šæ¸¸åŸæ–™è¯¦æƒ…",
    "å·¥ä¸šç”Ÿäº§åŸæ–™": "ä¸‹æ¸¸äº§å“è¯¦æƒ…",
    "æ€§è´¨": "ç‰©ç†åŒ–å­¦æ€§è´¨è¯¦æƒ…"
}}
```

## âš¡ ç‰¹åˆ«è¦æ±‚ (çŸ¥è¯†å›¾è°±ä¸“ç”¨)
- ğŸ” **CASå·/æµæ°´å·æ™ºèƒ½å¤„ç†**ï¼š
  - å¦‚è¾“å…¥ä¸ºæµæ°´å·ï¼Œå¿…é¡»æŸ¥è¯¢æ˜¯å¦å­˜åœ¨å¯¹åº”çš„æ ‡å‡†CASå·
  - å¦‚è¾“å…¥ä¸ºç©ºå€¼æˆ–æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä»æƒå¨æ•°æ®åº“æŸ¥è¯¢è¡¥å……æ ‡å‡†CASå·
  - ä¼˜å…ˆä½¿ç”¨å›½é™…CASå·ï¼Œç¡®ä¿å…¨çƒé€šç”¨æ€§å’Œæ•°æ®å…³è”æ€§
  - ä¿è¯æ¯ä¸ªåŒ–å­¦å“éƒ½æœ‰å”¯ä¸€ä¸”å‡†ç¡®çš„æ ‡è¯†ç¬¦
- ğŸ“Š **æ•°æ®æ¥æºæƒå¨æ€§**: ä¼˜å…ˆä½¿ç”¨PubChemã€ECHAç­‰æƒå¨æºï¼Œç¡®ä¿æ•°æ®è´¨é‡
- ğŸ¯ **å†…å®¹è¯¦ç»†å…·ä½“**: æ¯ä¸ªå­—æ®µéƒ½è¦è¯¦ç»†å¡«å†™ï¼Œé¿å…ä½¿ç”¨æ¨¡ç³Šæˆ–ç¬¼ç»Ÿçš„æè¿°ï¼Œä¸ºçŸ¥è¯†å›¾è°±æä¾›é«˜è´¨é‡çš„å±æ€§ä¿¡æ¯
- ğŸ”— **å…³è”æ€§æè¿°**: ç‰¹åˆ«æ³¨æ„äº§ä¸šé“¾ï¼ˆç”Ÿäº§æ¥æºã€å·¥ä¸šç”Ÿäº§åŸæ–™ï¼‰å’Œå±å®³ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ï¼Œè¿™æ˜¯æ„å»ºå…³ç³»å›¾è°±çš„æ ¸å¿ƒ
- ğŸ‡¨ğŸ‡³ **ç®€ä½“ä¸­æ–‡**: æ‰€æœ‰æè¿°å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡
- ğŸ“‹ **æ ¼å¼ä¸¥æ ¼ç»Ÿä¸€**: ä¸¥æ ¼éµå®ˆJSONè¾“å‡ºæ ¼å¼ï¼Œä¾¿äºçŸ¥è¯†å›¾è°±çš„è‡ªåŠ¨åŒ–ç»“æ„åŒ–å¤„ç†

## ğŸ’¡ å­—æ®µå¡«å†™æŒ‡å¯¼
- **CASå·æˆ–æµæ°´å·å­—æ®µ**: 
  - æ ‡å‡†CASå·ç¤ºä¾‹ï¼š64-17-5ï¼ˆä¹™é†‡ï¼‰ã€7732-18-5ï¼ˆæ°´ï¼‰
  - æµæ°´å·ç¤ºä¾‹ï¼š202401001ã€300015678ï¼ˆçº¯æ•°å­—æ ¼å¼ï¼‰
  - æ ¼å¼éªŒè¯ï¼šç¡®ä¿CASå·ç¬¦åˆ"æ•°å­—-æ•°å­—-æ•°å­—"æ ‡å‡†
- **åˆ«åå­—æ®µ**: åŒ…å«å­¦åã€ä¿—åã€å•†å“åã€è‹±æ–‡åç­‰ï¼Œç”¨åˆ†å·åˆ†éš”ï¼Œä»¥æä¾›ä¸°å¯Œçš„æ£€ç´¢å…¥å£
- **æµ“åº¦é˜ˆå€¼**: å°½é‡æä¾›å¤šç§ç‰©ç§ï¼ˆå¤§é¼ ã€å…”å­ç­‰ï¼‰å’Œå¤šç§é€”å¾„ï¼ˆç»å£ã€å¸å…¥ã€çš®è‚¤ï¼‰çš„æ¯’ç†å­¦æ•°æ®ï¼Œ**å‚è€ƒåŸåå½•"æµ“åº¦é˜ˆå€¼"å­—æ®µè¿›è¡Œè¯¦ç»†è¯´æ˜**ã€‚
- **è‡ªç„¶æ¥æº**: è¯¦ç»†æè¿°å¤©ç„¶å­˜åœ¨æƒ…å†µï¼ŒåŒ…æ‹¬åœ¨å“ªäº›æ¤ç‰©ã€åŠ¨ç‰©ã€çŸ¿ç‰©æˆ–å¾®ç”Ÿç‰©ä¸­å‘ç°ï¼Œä»¥åŠå¤©ç„¶æå–å·¥è‰º
- **äº§ä¸šé“¾ä¿¡æ¯**: è¦æ¸…æ™°åœ°ä½“ç°åŒ–å­¦å“åœ¨æ•´ä¸ªäº§ä¸šé“¾ä¸­çš„ä¸Šæ¸¸åŸæ–™å’Œä¸‹æ¸¸äº§å“å…³ç³»
- **æ€§è´¨æè¿°**: å°½é‡æä¾›å®šé‡æ•°æ®ï¼Œå¹¶æ³¨æ˜æµ‹è¯•æ¡ä»¶ï¼ˆå¦‚æ¸©åº¦ã€å‹åŠ›ï¼‰
- **æ•°æ®æ¥æºæ ‡æ³¨**: **ä»…åœ¨é¡¶å±‚ `data_source` å­—æ®µä¸­è¯´æ˜æœ¬æ¬¡æŸ¥è¯¢çš„ä¸»è¦ä¿¡æ¯æ¥æºï¼Œä¾‹å¦‚ "ç½‘ç»œæœç´¢ {{PubChem; ECHA}}" æˆ– "æ¨¡å‹çŸ¥è¯† {{æ¨¡å‹çŸ¥è¯†}}"ã€‚å…¶ä»–å­—æ®µæ— éœ€æ ‡æ³¨æ¥æºã€‚**

ç°åœ¨å¼€å§‹æŸ¥è¯¢å¹¶ç”Ÿæˆç”¨äºçŸ¥è¯†å›¾è°±çš„åŒ–å­¦å“è¯¦ç»†æ•°æ®ï¼š"""

            logger.debug(f"æˆåŠŸä¸ºåŒ–å­¦å“ '{chemical_name}' ç”Ÿæˆ prompt")
            return prompt

        except Exception as e:
            logger.error(f"ä¸ºåŒ–å­¦å“ '{chemical_name}' (CAS: {cas_number}) ç”Ÿæˆ prompt æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return None

    @staticmethod
    def extract_json_data(api_response_text: str) -> Tuple[Optional[Dict[str, Any]], str]:
        """
        ä»APIå“åº”ä¸­ç¨³å¥åœ°æå–å’Œè§£æJSONæ•°æ® - å¢å¼ºç‰ˆ
        åŒæ—¶æ£€æµ‹è”ç½‘æŸ¥æ‰¾çŠ¶æ€
        """
        if not api_response_text or not api_response_text.strip():
            return None, "APIè¿”å›ç©ºå“åº”"

        # é¢„å¤„ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤å¸¸è§çš„markdownæ ‡è®°
        cleaned_text = api_response_text.strip()
        
        # ç§»é™¤ä»£ç å—æ ‡è®°
        if cleaned_text.startswith('```json'):
            cleaned_text = cleaned_text[7:]
        elif cleaned_text.startswith('```'):
            cleaned_text = cleaned_text[3:]
        
        if cleaned_text.endswith('```'):
            cleaned_text = cleaned_text[:-3]
            
        cleaned_text = cleaned_text.strip()

        try:
            # å°è¯•ç›´æ¥è§£æ
            parsed_data = json.loads(cleaned_text)
            return parsed_data, "æˆåŠŸè§£æJSON"
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
            json_match = re.search(r'\{.*\}', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    parsed_data = json.loads(json_str)
                    return parsed_data, "æˆåŠŸé€šè¿‡æ­£åˆ™æå–å¹¶è§£æJSON"
                except json.JSONDecodeError as e:
                    return None, f"æå–çš„JSONå†…å®¹æ— æ•ˆ: {e}"
            else:
                return None, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå†…å®¹"
